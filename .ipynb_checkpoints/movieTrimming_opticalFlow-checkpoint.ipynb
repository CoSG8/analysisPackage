{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "import cv2\n",
    "import sys\n",
    "import os\n",
    "import tkinter\n",
    "import tkinter.filedialog\n",
    "import numpy as np\n",
    "from IPython.core.display import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open file\n",
    "root = tkinter.Tk()\n",
    "root.withdraw()\n",
    "fTyp = [(\"\",\"*\")]\n",
    "iDir = os.path.abspath(os.path.dirname('__file__'))\n",
    "# for Win\n",
    "# files = tkinter.filedialog.askopenfilenames(filetypes = fTyp,initialdir = iDir)\n",
    "# for Mac\n",
    "files = tkinter.filedialog.askopenfilenames(initialdir = iDir)\n",
    "videoPath = list(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/akitokosugi/analysisPackage/20170616_Mokuren_right_up_trim2_trimming'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "fName = os.path.basename(os.path.splitext(videoPath[i])[0])\n",
    "fNameExt = os.path.basename(os.path.splitext(videoPath[i])[1])\n",
    "pathTemp = [os.path.dirname(os.path.splitext(videoPath[i])[0]),fName + '_trimming']\n",
    "savePath = os.path.join(*pathTemp)\n",
    "os.makedirs(savePath, exist_ok=True)\n",
    "display(savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample (Udemy)\n",
    "count = 200\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 20, 0.03)\n",
    "lk_params = dict(winSize = (10,10), maxLevel = 5, criteria = criteria)\n",
    "cap = cv2.VideoCapture(videoPath[0])\n",
    "ret, frame = cap.read()\n",
    "frame_pre = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frame_now = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    feature_pre = cv2.goodFeaturesToTrack(frame_pre, count, 0.001, 5)\n",
    "    if feature_pre is None:\n",
    "        continue\n",
    "    feature_now, status, err = cv2.calcOpticalFlowPyrLK(frame_pre, frame_now, feature_pre, None, **lk_params)\n",
    "    for i in range(count):\n",
    "        pre_x = feature_pre[i][0][0]\n",
    "        pre_y = feature_pre[i][0][1]\n",
    "        now_x = feature_now[i][0][0]\n",
    "        now_y = feature_now[i][0][1]\n",
    "        cv2.line(frame, (pre_x,pre_y), (now_x,now_y), (255,0,0), 3)\n",
    "    cv2.imshow(\"img\",frame)\n",
    "    \n",
    "    frame_pre = frame_now.copy()\n",
    "    if cv2.waitKey(10) == 0x1b:\n",
    "        break\n",
    "\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# modified sample (Udemy)\n",
    "# BeamWalk\n",
    "# winSize = (30,30)\n",
    "# maxLevel = 2\n",
    "# criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 20, 0.03)\n",
    "# maxCount = 180\n",
    "# qualityLevel = 0.01\n",
    "# minDistance = 30\n",
    "# blockSize = 5;\n",
    "\n",
    "# Grasping\n",
    "winSize = (10,10)\n",
    "maxLevel = 5\n",
    "criteria = (cv2.TERM_CRITERIA_MAX_ITER | cv2.TERM_CRITERIA_EPS, 20, 0.03)\n",
    "maxCount = 150\n",
    "qualityLevel = 0.2\n",
    "minDistance = 5\n",
    "blockSize = 5;\n",
    "\n",
    "lk_params = dict(winSize = winSize,\n",
    "                 maxLevel = maxLevel, \n",
    "                 criteria = criteria)\n",
    "\n",
    "feature_params = dict(maxCorners = maxCount,\n",
    "                      qualityLevel = qualityLevel,\n",
    "                      minDistance = minDistance,\n",
    "                      blockSize = blockSize) \n",
    "\n",
    "cap = cv2.VideoCapture(videoPath[0])\n",
    "ret, frame = cap.read()\n",
    "frame_pre = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "while True:\n",
    "    diff_x = 0\n",
    "    diff_y = 0\n",
    "    \n",
    "    ret, frame = cap.read()\n",
    "    if ret == False:\n",
    "        break\n",
    "    frame_now = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "#     feature_pre = cv2.goodFeaturesToTrack(frame_pre, maxCount, qualityLevel, minDistance)\n",
    "    feature_pre = cv2.goodFeaturesToTrack(frame_pre, **feature_params)\n",
    "\n",
    "    if feature_pre is None:\n",
    "        continue\n",
    "    feature_now, status, err = cv2.calcOpticalFlowPyrLK(frame_pre, frame_now, feature_pre, None, **lk_params)\n",
    "    for i in range(len(feature_now)):\n",
    "        pre_x = feature_pre[i][0][0]\n",
    "        pre_y = feature_pre[i][0][1]\n",
    "        now_x = feature_now[i][0][0]\n",
    "        now_y = feature_now[i][0][1]\n",
    "        if now_x < 240:\n",
    "            diff_x += now_x - pre_x\n",
    "            diff_y += now_y - pre_y\n",
    "#         diff_x += now_x - pre_x\n",
    "#         diff_y += now_y - pre_y        \n",
    "        cv2.line(frame, (pre_x,pre_y), (now_x,now_y), (255,0,0), 3)\n",
    "\n",
    "    cv2.arrowedLine(frame, (40,40), (int(diff_x),int(diff_y)), (0,0,255), thickness=3, tipLength = 0.1)\n",
    "    cv2.imshow(\"img\",frame)\n",
    "    \n",
    "    frame_pre = frame_now.copy()\n",
    "    if cv2.waitKey(10) == 0x1b:\n",
    "        break\n",
    "\n",
    "cv2.waitKey(1)\n",
    "cv2.destroyAllWindows()\n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[223.46466 , 172.24861 ]],\n",
       "\n",
       "       [[230.51413 , 172.22284 ]],\n",
       "\n",
       "       [[484.0305  , 312.00427 ]],\n",
       "\n",
       "       [[ 62.021194, 331.9569  ]],\n",
       "\n",
       "       [[486.03616 , 327.0012  ]],\n",
       "\n",
       "       [[220.05557 , 179.5888  ]],\n",
       "\n",
       "       [[440.00977 , 332.0273  ]],\n",
       "\n",
       "       [[507.02658 , 316.00845 ]],\n",
       "\n",
       "       [[456.0382  , 315.00992 ]],\n",
       "\n",
       "       [[497.04803 , 245.97304 ]],\n",
       "\n",
       "       [[489.0994  , 298.98016 ]],\n",
       "\n",
       "       [[235.77042 , 186.2919  ]],\n",
       "\n",
       "       [[218.34047 , 166.1495  ]],\n",
       "\n",
       "       [[490.11435 , 307.9713  ]],\n",
       "\n",
       "       [[453.02896 , 328.97748 ]],\n",
       "\n",
       "       [[343.01944 , 281.00464 ]],\n",
       "\n",
       "       [[480.07538 , 315.0172  ]],\n",
       "\n",
       "       [[451.0067  , 322.03857 ]],\n",
       "\n",
       "       [[ 56.010387, 345.99048 ]],\n",
       "\n",
       "       [[413.02402 , 369.99432 ]],\n",
       "\n",
       "       [[489.03726 , 317.99988 ]],\n",
       "\n",
       "       [[125.14814 , 163.14331 ]],\n",
       "\n",
       "       [[401.0039  , 379.9582  ]],\n",
       "\n",
       "       [[434.97525 , 326.98425 ]],\n",
       "\n",
       "       [[454.03723 , 302.05365 ]],\n",
       "\n",
       "       [[493.97946 , 326.90436 ]],\n",
       "\n",
       "       [[184.4487  , 215.54517 ]],\n",
       "\n",
       "       [[476.15726 , 312.01877 ]],\n",
       "\n",
       "       [[417.99457 , 328.0761  ]]], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "417.99457"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "now_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def opticalFlowAnalysis(filename,videofile_path,savefile_path):\n",
    "\n",
    "    sumVal = 0\n",
    "    preSumVal = 0\n",
    "    framenum = 0\n",
    "    trialnum = 0\n",
    "    x_mean = 0\n",
    "    y_mean = 0\n",
    "    preY_mean = 0\n",
    "    x_array = []\n",
    "    y_array = []\n",
    "    area_array = []\n",
    "    orbit = []\n",
    "    startframe = []\n",
    "    # Shi-Tomasiのコーナー検出パラメータ\n",
    "#     feature_params = dict( maxCorners = 100,\n",
    "#                            qualityLevel = 0.3,\n",
    "#                            minDistance = 7,\n",
    "#                            blockSize = 7,\n",
    "#                            gradientSize = 3)\n",
    "    feature_params = dict( maxCorners = 100,\n",
    "                           qualityLevel = 0.001,\n",
    "                           minDistance = 5)\n",
    "    \n",
    "    # Lucas-Kanade法のパラメータ\n",
    "    lk_params = dict( winSize  = (15,15),\n",
    "                      maxLevel = 2,\n",
    "                      criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "    # 最初のフレームの処理\n",
    "    cap = cv2.VideoCapture(videofile_path)\n",
    "    totalFramenum = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "    ret, frame = cap.read()\n",
    "    gray_prev = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY),\n",
    "#     feature_prev = cv2.goodFeaturesToTrack(gray_prev, **feature_params)\n",
    "    feature_prev = cv2.goodFeaturesToTrack(gray_prev, 100, 0.01, 5)\n",
    "    mask = np.zeros_like(frame)\n",
    "\n",
    "    while(True):\n",
    "\n",
    "        # Frame capture\n",
    "        framenum += 1\n",
    "        ret,frame = cap.read()\n",
    "        if ret == False:\n",
    "            break\n",
    "\n",
    "        # グレースケールに変換\n",
    "        gray_next = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # オプティカルフロー検出\n",
    "        feature_next, status, err = cv2.calcOpticalFlowPyrLK(gray_prev, gray_next, feature_prev, None, **lk_params)\n",
    "\n",
    "        # オプティカルフローを検出した特徴点を選別（0：検出せず、1：検出した）\n",
    "        good_prev = feature_prev[status == 1]\n",
    "        good_next = feature_next[status == 1]\n",
    "\n",
    "        # オプティカルフローを描画\n",
    "        for i, (next_point, prev_point) in enumerate(zip(good_next, good_prev)):\n",
    "            prev_x, prev_y = prev_point.ravel()\n",
    "            next_x, next_y = next_point.ravel()\n",
    "            mask = cv2.line(mask, (next_x, next_y), (prev_x, prev_y), color[i].tolist(), 2)\n",
    "            frame = cv2.circle(frame, (next_x, next_y), 5, color[i].tolist(), -1)\n",
    "        img = cv2.add(frame, mask)\n",
    "\n",
    "        # ウィンドウに表示\\\n",
    "        cv2.imshow('window', img)\n",
    "\n",
    "        # 次のフレーム、ポイントの準備\n",
    "        gray_prev = gray_next.copy()\n",
    "        feature_prev = good_next.reshape(-1, 1, 2)\n",
    "        end_flag, frame = cap.read()\n",
    "\n",
    "\n",
    "    cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startFrame, trialNum = opticalFlowAnalysis(fName,videoPath[i],savePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
